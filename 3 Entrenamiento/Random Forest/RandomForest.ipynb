{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest\n",
    "\n",
    "No entiende las dependencias temporales. -> Añadir en la misma fila los datos de los días anteriores con los que se quiere predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Normalization: Min-Max Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inPath = \"../../1 Preprocesado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ficheros de datos\n",
    "polen = pd.read_csv(f\"{inPath}/polen/gramineas.csv\")\n",
    "tiempo = pd.read_csv(f\"{inPath}/tiempo/Getafe.csv\")\n",
    "\n",
    "# Unimos los datos\n",
    "datos = pd.merge(polen, tiempo, on='fecha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes\n",
    "ANTICIPACION = 1 # Número de días de anticipación con los que se predice\n",
    "NUM_DIAS = 15    # Número de días en base a los que se predice\n",
    "MODEL_FILE_NAME = f'random_forest{NUM_DIAS}_{ANTICIPACION}.pkl' #Archivo de guardado del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepación de los datos para el modelo de Random Forest\n",
    "# Ordenamos los datos por fecha\n",
    "datos = datos.sort_values('fecha')\n",
    "\n",
    "# Creamos las columnas con los datos de los días anteriores\n",
    "for i in range(1, NUM_DIAS + 1):\n",
    "    for columna in ['granos_de_polen', 'prec', 'tmin', 'tmax', 'dir', 'velmedia', 'racha', 'sol']:\n",
    "        # Supress SettingWithCopyWarning\n",
    "        datos = datos.copy()\n",
    "        datos[f'{columna}_{i}'] = datos[columna].shift(i)\n",
    "\n",
    "# Eliminamos los días que no tienen todos los datos\n",
    "datos = datos.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columna para los meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir columna del mes\n",
    "datos['mes'] = pd.to_datetime(datos['fecha']).dt.month\n",
    "datos = datos.drop(columns=['fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos los datos (no es necesario para Random Forest)\n",
    "# scaler = StandardScaler()\n",
    "# datos = pd.DataFrame(scaler.fit_transform(datos), columns=datos.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos en entrenamiento y test\n",
    "X = datos.drop(columns=['granos_de_polen'])\n",
    "y = datos['granos_de_polen']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización. Es importante destacar que la separación en el conjunto de entrenamiento y el conjunto de test no está mezclada. Estos se debe a que al ser datos con dependencias temporales, no se deben mezclar. Si no estaríamos probando el modelo habiendo entrenado con datos posteriores en el tiempo (sería como si pudiera ver el futuro, pero en la realidad no será así)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de los datos (sepamos los datos de entrenamiento y test)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y_train.index, y_train, label='Train')\n",
    "plt.plot(y_test.index, y_test, label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento (o carga) del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celda de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creación del modelo\n",
    "# model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# # Entrenamiento del modelo\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo (si ya está entrenado y no queremos volver a entrenarlo)\n",
    "if model is None:\n",
    "  model = joblib.load(MODEL_FILE_NAME)\n",
    "  print('Modelo cargado')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo utilizando el conjunto de prueba\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('MSE:', mse)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print('RMSE:', rmse)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('MAE:', mae)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importancia de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de las características\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, X.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de las características más importantes (las 10 primeras)\n",
    "import seaborn as sns\n",
    "color_palette = sns.color_palette(\"Spectral\", len([X.columns[i] for i in indices[:10]]))\n",
    "plt.figure(figsize=(15, 7))\n",
    "sns.barplot(x=[X.columns[i] for i in indices[:10]], y=importances[indices[:10]], palette=color_palette, hue=[X.columns[i] for i in indices[:10]])\n",
    "plt.title('Importancia de las características')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicción sobre el conjunto de datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de dispersión de los valores reales frente a los predichos\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Valores reales')\n",
    "plt.ylabel('Valores predichos')\n",
    "plt.title('Valores reales vs Valores predichos')\n",
    "# Línea de tendencia\n",
    "z = np.polyfit(y_test, y_pred, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test, p(y_test), color='darkgreen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardado del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo\n",
    "joblib.dump(model, MODEL_FILE_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
