{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inPath = \"../../1 Preprocesado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ficheros de datos\n",
    "polen = pd.read_csv(f\"{inPath}/polen/gramineasGETA.csv\")\n",
    "tiempo = pd.read_csv(f\"{inPath}/tiempo/Getafe.csv\")\n",
    "\n",
    "# Unimos los datos\n",
    "datos = pd.merge(polen, tiempo, on='fecha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes\n",
    "ANTICIPACION = 1 # Número de días de anticipación con los que se predice\n",
    "NUM_DIAS = 15   # Número de días en base a los que se predice\n",
    "MODEL_FILE_NAME = f'XGBoost{NUM_DIAS}_{ANTICIPACION}.pkl' #Archivo de guardado del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepación de los datos para el modelo de Random Forest\n",
    "# Ordenamos los datos por fecha\n",
    "datos = datos.sort_values('fecha')\n",
    "\n",
    "# Creamos las columnas con los datos de los días anteriores\n",
    "for i in range(1, NUM_DIAS + 1):\n",
    "    for columna in ['granos_de_polen', 'prec', 'tmin', 'tmax', 'dir', 'velmedia', 'racha', 'sol']:\n",
    "        # Supress SettingWithCopyWarning\n",
    "        datos = datos.copy()\n",
    "        datos[f'{columna}_{i}'] = datos[columna].shift(i)\n",
    "\n",
    "# Eliminamos los días que no tienen todos los datos\n",
    "datos = datos.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posibles mejoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quedarse solo con los meses de mayo a junio (todos los años)\n",
    "# (periodo de polinización de las gramíneas)\n",
    "# datos = datos[(datos['fecha'].str[5:7] == '05') | (datos['fecha'].str[5:7] == '06')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir columna de numero de semana (calculo a mano)\n",
    "datos['semana'] = pd.to_datetime(datos['fecha']).dt.dayofyear // 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ['prec', 'tmin', 'tmax', 'dir', 'velmedia', 'racha', 'sol']\n",
    "# datos = datos.drop(columns=[col for col in datos.columns if col.startswith('prec_')])\n",
    "# datos = datos.drop(columns=[col for col in datos.columns if col.startswith('tmin_')])\n",
    "# datos = datos.drop(columns=[col for col in datos.columns if col.startswith('tmax_')])\n",
    "# datos = datos.drop(columns=[col for col in datos.columns if col.startswith('dir_')])\n",
    "# # datos = datos.drop(columns=[col for col in datos.columns if col.startswith('velmedia_')])\n",
    "# datos = datos.drop(columns=[col for col in datos.columns if col.startswith('racha_')])\n",
    "# datos = datos.drop(columns=[col for col in datos.columns if col.startswith('sol_')])\n",
    "\n",
    "# datos = datos.drop(columns=['tmin', 'dir', 'racha', 'sol'])\n",
    "# datos = datos.drop(columns=['prec', 'tmin', 'tmax', 'dir', 'velmedia', 'racha', 'sol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitar columnas que empiezan por granos_de_polen_\n",
    "# datos = datos.drop(columns=[col for col in datos.columns if col.startswith('granos_de_polen_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos la columna de fecha\n",
    "datos = datos.drop(columns=['fecha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos en entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos los datos en entrenamiento y test\n",
    "X = datos.drop(columns=['granos_de_polen'])\n",
    "y = datos['granos_de_polen']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos los datos (no es necesario para Random Forest)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Escalar los datos \n",
    "# scaler = MinMaxScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de los datos (sepamos los datos de entrenamiento y test)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y_train.index, y_train, label='Train')\n",
    "plt.plot(y_test.index, y_test, label='Test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento (o carga) del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "model = xgb.XGBRegressor(n_estimators=200, learning_rate=0.25, random_state=42)\n",
    "model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo utilizando el conjunto de prueba\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('MSE:', mse)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print('RMSE:', rmse)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('MAE:', mae)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas con variables ordinales (alto-medio-bajo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classification thresholds\n",
    "low_threshold = 25\n",
    "medium_threshold = 50\n",
    "\n",
    "def classify_label(value):\n",
    "    if value < low_threshold:\n",
    "        return 'Low'\n",
    "    elif value < medium_threshold:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "# Classify the predictions based on the thresholds\n",
    "y_true = [classify_label(value) for value in y_test]  # Replace classify_label with your own function\n",
    "y_pred_clas = [classify_label(value) for value in y_pred]  # Replace classify_label with your own function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create the confusion matrix\n",
    "labels = ['Low', 'Medium', 'High']\n",
    "cm = confusion_matrix(y_true, y_pred_clas, labels=labels)\n",
    "\n",
    "# Display the confusion matrix with a heatmap\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas (categóricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar métricas de clasificación\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Display the classification report\n",
    "print(classification_report(y_true, y_pred_clas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de las características\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, X.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de las características más importantes (las 10 primeras)\n",
    "import seaborn as sns\n",
    "color_palette = sns.color_palette(\"Spectral\", len([X.columns[i] for i in indices[:10]]))\n",
    "plt.figure(figsize=(15, 7))\n",
    "sns.barplot(x=[X.columns[i] for i in indices[:10]], y=importances[indices[:10]], palette=color_palette, hue=[X.columns[i] for i in indices[:10]])\n",
    "plt.title('Importancia de las características')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de dispersión de los valores reales frente a los predichos\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Valores reales')\n",
    "plt.ylabel('Valores predichos')\n",
    "plt.title('Valores reales vs Valores predichos')\n",
    "# Línea de tendencia\n",
    "z = np.polyfit(y_test, y_pred, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test, p(y_test), color='darkgreen')\n",
    "# Línea de 45 grados\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de la predicción con puntos\n",
    "plt.plot(y_test.index, y_test, label='Real', color='blue', marker='o')\n",
    "plt.plot(y_test.index, y_pred, label='Predicción', color='red', marker='x')\n",
    "# Recortar a fragmentos cortos para poder ver lo que pasa\n",
    "# plt.xlim(3175, 3220)\n",
    "# plt.xlim(3520, 3560)\n",
    "plt.xlim(4080, 4130)\n",
    "# Dibujar líneas horizontales para los umbrales\n",
    "plt.axhline(y=low_threshold, color='green', linestyle='--', label='Low threshold')\n",
    "plt.axhline(y=medium_threshold, color='orange', linestyle='--', label='Medium threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardado del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo\n",
    "joblib.dump(model, MODEL_FILE_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
